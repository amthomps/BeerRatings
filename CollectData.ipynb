{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data for Beers and Breweries\n",
    "This is a tool to predict the rating of a beer based on the brewery, style, and location.\n",
    "\n",
    "Our first task is to find the information we want for each beer in the html.  Going to the URL https://untappd.com/b/one-barrel-brewing-company-fanny-pack/2389998 gives us a page for one beer.  At the top of the page, we can see the name of the beer, the style, and the brewery.  There is also a table that tells us the number of ratings, the date added, the ABV, IBU, and importantly - the rating!  Everything we want is in that first block.  There are probably interesting questions to be asked from analyzing the rest of the data on the page, but it's beyond what we need currently.  \n",
    "Let's load the first page of HTML and see what we can extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#install packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Enter the account info to login to the Untappd site\n",
    "loginInfo = {\n",
    "    'username': 'YourUsernameHere',\n",
    "    'password': 'YourPasswordHere'\n",
    "}\n",
    "\n",
    "#Go to the login page\n",
    "LoginURL = 'https://untappd.com/login'\n",
    "    \n",
    "#Establish a session and enter the login info\n",
    "with requests.Session() as session:\n",
    "    post = session.post(LoginURL, data=loginInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Beer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "\n",
    "#loop through the urls of beers within a range of ID's\n",
    "for m in range(1200450, 1200600):\n",
    "    print(\"Getting data for \" + str(m))\n",
    "    url = 'https://untappd.com/b/a/' + str(m)\n",
    "    page = session.get(url, headers = {'User-agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36'})\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    #Get the title info containing the name of the beer and the brewery\n",
    "    title = soup.find('title').get_text()\n",
    "    title = title.split(' - ')\n",
    "    \n",
    "    if len(title) < 2: #skip to the next page if both the name and brewery are not found\n",
    "        print('invalid page')\n",
    "        time.sleep(20)\n",
    "        continue\n",
    "        \n",
    "    name = title[0]\n",
    "    brewery = title[1]\n",
    "    \n",
    "    #Get the style of the beer (i.e. stout, IPA)\n",
    "    style = soup.find(attrs={'class':'style'}).get_text()\n",
    "    \n",
    "    #Get the rating for the beer\n",
    "    rating = soup.find(attrs={'class':'num'}).get_text()\n",
    "    \n",
    "    if rating == '(N/A)': #skip to the next page if the beer has no rating (occurs if # of reviews < 10)\n",
    "        print('no rating')\n",
    "        time.sleep(20)\n",
    "        continue\n",
    "    \n",
    "    #Get ABV, alcohol by volume\n",
    "    abv = soup.find(attrs={'class':'abv'}).get_text()\n",
    "    \n",
    "    #Get IBU, international biterness units\n",
    "    ibu = soup.find(attrs={'class':'ibu'}).get_text()\n",
    "    \n",
    "    #Get the number of people who have reviewed the beer\n",
    "    raters = soup.find(attrs={'class':'raters'}).get_text()\n",
    "    \n",
    "    #Get the date the beer was added to the website\n",
    "    date = soup.find(attrs={'class':'date'}).get_text()\n",
    "    \n",
    "    #Get the untappd url suffix for the brewery\n",
    "    brewerylinkline = soup.find(attrs={'class':'brewery'})\n",
    "    brewerylinkhtml = brewerylinkline.find('a')\n",
    "    brewerylink = brewerylinkhtml.get('href')\n",
    "    \n",
    "    #Write these data to a csv\n",
    "    with open('untappd2.csv', 'a') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow([str(m), name, brewery, style, rating, abv, ibu, raters, date, brewerylink])\n",
    "    \n",
    "    #Pause 10 seconds to avoid overloading the server\n",
    "    time.sleep(20)\n",
    "    \n",
    "print('Finished collecting data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Brewery Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of unique breweries is 287 items long\n",
      "['/FactionBrewing', '/BugnuttyBrew', '/goldencoastmead', '/tailgatebeer', '/Rhinegeist', '/WasserhundBrewingCompany', '/KannahCreekBrewingCompany', '/902Brewing', '/DandyAlesyyc', '/AlpineBeerCo']\n",
      "list of breweries missing data is 15 items long\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "beerdf = pd.read_csv(\"untappd2.csv\", header=None)\n",
    "#make a list of brewery url suffixes\n",
    "brewerylist = beerdf.loc[:, 9].tolist()\n",
    "\n",
    "#remove duplicate items (this may re-order the list, but this is fine)\n",
    "breweryshort = list(set(brewerylist))\n",
    "print('list of unique breweries is ' + str(len(breweryshort)) + ' items long')\n",
    "\n",
    "#print the first 10 items\n",
    "print(brewerylist[0:10])\n",
    "\n",
    "#check if we already have info for some of these breweries\n",
    "brewdf = pd.read_csv(\"breweries.csv\", header=None)\n",
    "brewinfo = brewdf.loc[:, 0].tolist()\n",
    "newbrew = list(set(breweryshort) - set(brewinfo))\n",
    "print('list of breweries missing data is ' + str(len(newbrew)) + ' items long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(newbrew[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "\n",
    "#loop through the urls of beers within a range of ID's\n",
    "for brewerylink in newbrew[0:94]:\n",
    "    print(\"Getting data for \" + brewerylink)\n",
    "    url = 'https://untappd.com' + brewerylink\n",
    "    page = session.get(url, headers = {'User-agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/45.0.2454.101 Safari/537.36'})\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    #get brewery location, split into city and state/country\n",
    "    location = soup.find(attrs={'class':'brewery'}).get_text()\n",
    "    location = location.split(', ')\n",
    "    \n",
    "    if len(location) < 2: #skip to the next page if both the city and state/country are not found\n",
    "        print('invalid page')\n",
    "        time.sleep(25)\n",
    "        continue\n",
    "        \n",
    "    city = location[0]\n",
    "    statecountry = location[1]\n",
    "    \n",
    "    #get the type of the brewery (i.e. microbrewery)\n",
    "    b_type = soup.find(attrs={'class':'style'}).get_text()\n",
    "\n",
    "    #get the overall brewery rating\n",
    "    b_rating = soup.find(attrs={'class':'num'}).get_text()\n",
    "\n",
    "    if b_rating == '(N/A)': #skip to the next page if the beer has no rating (occurs if # of reviews < 10)\n",
    "        print('no rating')\n",
    "        time.sleep(22)\n",
    "        continue\n",
    "\n",
    "    #get the number of beers the brewery has in the system\n",
    "    b_count = soup.find(attrs={'class':'count'}).get_text()\n",
    "\n",
    "    #get the number of raters\n",
    "    b_raters = soup.find(attrs={'class':'raters'}).get_text()\n",
    "\n",
    "    #get the date the brewery was added\n",
    "    b_date = soup.find(attrs={'class':'date'}).get_text()\n",
    "    \n",
    "    #Write these data to a csv\n",
    "    with open('breweries.csv', 'a') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow([brewerylink, city, statecountry, b_type, b_rating, b_count, b_raters, b_date])\n",
    "    \n",
    "    #Pause 10 seconds to avoid overloading the server\n",
    "    time.sleep(21)\n",
    "    \n",
    "print('Finished collecting data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
